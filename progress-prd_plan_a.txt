# SpreadsheetValidator — AG-UI State-Driven React Cards - Progress Log

## Project Context
- PRD: prd_plan_a.json
- 6 phases, 15 total stories
- TDD approach: RED -> GREEN -> REFACTOR for every story
- Architecture: ADK agents + ag-ui-adk SSE + CopilotKit useCoAgentStateRender + custom React cards

## Completed Stories
- 1.1: Project scaffold with pyproject.toml and directory structure
- 1.2: PipelineState Pydantic model with aligned status values
- 1.3: Agent callbacks: state initialization and prompt injection
- 2.1: Ingestion tools: request_file_upload, ingest_file, ingest_uploaded_file
- 2.2: Validation tools: validate_data, request_user_fix, write_fix
- 2.3: Processing tools: transform_data, package_results
- 3.1: Sub-agents: IngestionAgent, ValidationAgent, ProcessingAgent
- 3.2: Root agent: SpreadsheetValidatorAgent orchestrator
- 4.1: FastAPI server with AG-UI SSE endpoint and REST endpoints

## Current Phase
Phase 1 - Project Scaffold & Models (COMPLETE)
Phase 2 - Tools (COMPLETE)
Phase 3 - Agent Core (COMPLETE)
Phase 4 - Backend Server (COMPLETE)
Phase 5 - Frontend Webapp (IN PROGRESS)

## Learnings & Patterns
(To be updated as implementation progresses)

## Blockers & Issues
(none yet)

## Quality Gates
- Each story follows TDD: write test first, then implement
- Commit message format: feat|fix|refactor(scope): description
- Backend: ruff check . && ruff format --check .
- Frontend: npm run build && npm run lint
- Coverage: >=80% line coverage for new modules

---

## Iteration Log

### Story 1.1: Project scaffold with pyproject.toml and directory structure
**Completed:** 2026-02-01
**Phase:** 1 - Project Scaffold & Models

**What Was Done:**
- Created pyproject.toml with all required dependencies (google-adk, fastapi, ag-ui-adk, pandas, etc.)
- Set up app/ package with agents/ and tools/ sub-packages
- Created tests/foundation/test_scaffold.py with 5 scaffold verification tests
- Added tests/conftest.py and test __init__.py files
- Created .env.example with GOOGLE_GENAI_USE_VERTEXAI and GOOGLE_API_KEY
- Added [dependency-groups] dev section so `uv sync` installs dev deps by default
- Added [tool.hatch.build.targets.wheel] packages config for hatchling

**Verification:**
- uv sync: PASS (131 packages installed)
- pytest tests/foundation/test_scaffold.py -v: PASS (5 passed)
- ruff check . && ruff format --check .: PASS
- python -c 'import app': PASS
- pytest --co: PASS (5 tests collected)
- All acceptance criteria: Satisfied

**Learnings:**
- Hatchling requires `[tool.hatch.build.targets.wheel] packages = ["app"]` when the package name doesn't match the project name
- `uv sync` without `--all-extras` won't install `[project.optional-dependencies]`, but `[dependency-groups]` are installed by default
- Must use `uv run pytest` (not bare `pytest`) to ensure the virtual env is used

### Story 1.2: PipelineState Pydantic model with aligned status values
**Completed:** 2026-02-01
**Phase:** 1 - Project Scaffold & Models

**What Was Done:**
- Created app/models.py with PipelineState Pydantic model
- 10-value Status Literal: IDLE, UPLOADING, RUNNING, VALIDATING, WAITING_FOR_USER, FIXING, TRANSFORMING, PACKAGING, COMPLETED, FAILED
- All fields with sensible defaults (status="IDLE", empty lists/dicts, validation_complete=False, usd_rounding="cents")
- No ui_events field — Plan A uses state-driven rendering
- Created tests/foundation/test_pipeline_state.py with 23 tests across 3 test classes

**Verification:**
- pytest tests/foundation/test_pipeline_state.py -v: PASS (23 passed)
- pytest tests/ -v: PASS (28 passed, including story 1.1 tests)
- ruff check . && ruff format --check .: PASS
- All acceptance criteria: Satisfied

**Learnings:**
- ruff format adjusts blank line spacing — run `ruff format` before committing to avoid format check failures
- PipelineState uses `list[dict]` and `dict[str, str]` for mutable defaults — Pydantic handles default factory automatically

### Story 1.3: Agent callbacks: state initialization and prompt injection
**Completed:** 2026-02-01
**Phase:** 1 - Project Scaffold & Models

**What Was Done:**
- Created app/callbacks.py with three callback functions
- on_before_agent: idempotent state initialization, fills missing keys with PipelineState defaults using fresh copies for mutable values
- before_model_modifier: injects pipeline state summary into root agent's system instruction only (SpreadsheetValidatorAgent)
- after_model_modifier: no-op that returns None, logs for debugging
- Created tests/agents/test_callbacks.py with 7 tests across 3 test classes
- Created tests/agents/__init__.py

**Verification:**
- pytest tests/agents/test_callbacks.py -v: PASS (7 passed)
- pytest tests/ -v: PASS (35 passed, all stories)
- ruff check . && ruff format --check .: PASS
- All acceptance criteria: Satisfied

**Learnings:**
- Using lambdas for mutable defaults in _STATE_DEFAULTS dict ensures fresh copies on each call
- PropertyMock on type() is needed to mock agent_name as a property on MagicMock
- Phase 1 is now complete — all 3 foundation stories done

### Story 2.1: Ingestion tools: request_file_upload, ingest_file, ingest_uploaded_file
**Completed:** 2026-02-01
**Phase:** 2 - Tools

**What Was Done:**
- Created app/tools/ingestion.py with 3 tools: request_file_upload, ingest_file, ingest_uploaded_file
- request_file_upload returns waiting_for_upload status with accepted formats (.csv, .xlsx, .xls)
- ingest_file reads CSV/XLSX from disk via pandas, populates state with records, columns, file_path, file_name, status=RUNNING
- ingest_uploaded_file reads from ADK ArtifactService via load_artifact(), parses CSV/XLSX with fallback
- Updated app/tools/__init__.py to export all 3 ingestion tools
- Created tests/fixtures/test_data.csv with 3 sample rows
- Created tests/tools/test_ingestion.py with 11 tests across 3 test classes

**Verification:**
- pytest tests/tools/test_ingestion.py -v: PASS (11 passed)
- pytest tests/ -v: PASS (46 passed, all stories including previous)
- ruff check . && ruff format --check .: PASS
- All acceptance criteria: Satisfied

**Learnings:**
- MagicMock state dict works well for tool_context.state mocking — no need for complex ADK ToolContext setup
- AsyncMock from unittest.mock is required for load_artifact since it's an async method
- Pandas read_csv/read_excel handles the heavy lifting; tools just bridge between ADK state and pandas

### Story 2.2: Validation tools: validate_data, request_user_fix, write_fix
**Completed:** 2026-02-01
**Phase:** 2 - Tools

**What Was Done:**
- Created app/tools/validation.py with 3 tools: validate_data, request_user_fix, write_fix
- validate_data enforces 7 business rules: employee_id format+uniqueness, dept enum, amount range (0,100000], currency ISO 4217 enum, spend_date YYYY-MM-DD+not-future, vendor non-empty, fx_rate required for non-USD with range [0.1,500]
- request_user_fix appends fix request to state["pending_fixes"] and sets status=WAITING_FOR_USER
- write_fix updates the record value, removes from pending_fixes, transitions to RUNNING (empty) or FIXING (remaining)
- Updated app/tools/__init__.py to export all 6 tools (3 ingestion + 3 validation)
- Created tests/tools/test_validation.py with 23 tests across 9 test classes

**Verification:**
- pytest tests/tools/test_validation.py -v: PASS (23 passed)
- pytest tests/ -v: PASS (69 passed, all stories including previous)
- ruff check . && ruff format --check .: PASS
- All acceptance criteria: Satisfied

**Learnings:**
- NaN check via `fx_rate != fx_rate` covers the pandas NaN case for missing fx_rate values
- The as_of_date parameter on validate_data allows overriding the reference date for future-date checks (useful for testing)
- ruff format needs to be run after writing code — spec-provided code often needs reformatting for line length and dict literal style

### Story 2.3: Processing tools: transform_data, package_results
**Completed:** 2026-02-01
**Phase:** 2 - Tools

**What Was Done:**
- Created app/tools/processing.py with 2 tools: transform_data, package_results
- transform_data adds static (default_value) or computed (expression) columns to all records, updates dataframe_columns, sets status=TRANSFORMING
- package_results separates valid/invalid rows by validation_errors indices, creates success.xlsx and errors.xlsx via pandas to_excel, saves as ADK artifacts via Part.from_bytes and tool_context.save_artifact(), sets state artifacts and status=COMPLETED
- Updated app/tools/__init__.py to export all 8 tools (3 ingestion + 3 validation + 2 processing)
- Created tests/tools/test_processing.py with 10 tests across 3 test classes

**Verification:**
- pytest tests/tools/test_processing.py -v: PASS (10 passed)
- pytest tests/ -v: PASS (79 passed, all stories including previous)
- ruff check . && ruff format --check .: PASS
- All acceptance criteria: Satisfied

**Learnings:**
- The spec used `Part.from_data()` but the installed google-genai version uses `Part.from_bytes(data=..., mime_type=...)` — always check the actual API surface
- Part.from_bytes returns an object with `inline_data.data` (bytes) and `inline_data.mime_type` — tests can verify Excel validity by reading artifact.inline_data.data with pd.read_excel
- Phase 2 is now complete — all 3 tool stories done (ingestion, validation, processing)

### Story 3.1: Sub-agents — IngestionAgent, ValidationAgent, ProcessingAgent
**Completed:** 2026-02-01
**Phase:** 3 - Agent Core

**What Was Done:**
- Created app/agents/ingestion.py with IngestionAgent (LlmAgent, 3 tools, output_key='ingestion_result')
- Created app/agents/validation.py with ValidationAgent (LlmAgent, 3 tools, output_key='validation_result')
- Created app/agents/processing.py with ProcessingAgent (LlmAgent, 2 tools, output_key='processing_result')
- Updated app/agents/__init__.py to export all three agents
- Created tests/agents/test_sub_agents.py with 19 tests across 4 test classes
- No render_a2ui tool on any agent — Plan A state-driven rendering

**Verification:**
- pytest tests/agents/test_sub_agents.py -v: PASS (19 passed)
- pytest tests/ -v: PASS (98 passed, all stories including previous)
- ruff check . && ruff format --check .: PASS
- All acceptance criteria: Satisfied

**Learnings:**
- The spec uses `from google.adk import LlmAgent` but the installed version requires `from google.adk.agents import LlmAgent` — google.adk only exports `Agent` at top level
- LlmAgent constructor accepts kwargs via pydantic model (name, model, instruction, tools, output_key) — works as expected
- Tool functions passed directly to LlmAgent.tools retain their __name__ attribute, making test assertions straightforward

### Story 3.2: Root agent — SpreadsheetValidatorAgent orchestrator
**Completed:** 2026-02-01
**Phase:** 3 - Agent Core

**What Was Done:**
- Created app/agents/root_agent.py with SpreadsheetValidatorAgent (Agent, 3 sub-agents, no tools, 3 callbacks)
- Created app/agent.py with ADK App wrapper (name='spreadsheet_validator')
- Updated app/__init__.py to export root_agent for ADK discovery
- Created tests/agents/test_root_agent.py with 14 tests across 5 test classes

**Verification:**
- pytest tests/agents/test_root_agent.py -v: PASS (14 passed)
- pytest tests/ -v: PASS (112 passed, all stories including previous)
- ruff check . && ruff format --check .: PASS
- All acceptance criteria: Satisfied

**Learnings:**
- The spec uses `from google.adk import App` but the installed version requires `from google.adk.apps import App` — `google.adk` re-exports `Agent` but not `App`
- Agent constructor uses pydantic kwargs, so all fields (sub_agents, before_agent_callback, etc.) are passed directly
- Phase 3 is now complete — both agent core stories done (sub-agents + root orchestrator)

### Story 4.1: FastAPI server with AG-UI SSE endpoint and REST endpoints
**Completed:** 2026-02-01
**Phase:** 4 - Backend Server

**What Was Done:**
- Created app/server.py with FastAPI server, CORS middleware, and all REST endpoints
- AG-UI SSE endpoint at /agent via ADKAgent.from_app() and add_adk_fastapi_endpoint()
- REST endpoints: GET /health, POST /run, POST /upload, GET /runs, GET /runs/{id}, GET /artifacts/{name}, POST /feedback
- InMemorySessionService and InMemoryArtifactService for development
- Session tracking via _thread_to_session and _sessions dicts
- Heavy keys (dataframe_records, dataframe_columns, validation_errors, pending_fixes) stripped from /runs listing
- Created tests/e2e/__init__.py and tests/e2e/test_server.py with 13 tests across 8 test classes
- Created tests/server/__init__.py for future server tests
- No monkey-patches, no render_a2ui anywhere in server.py

**Verification:**
- pytest tests/e2e/test_server.py -v: PASS (13 passed)
- pytest tests/ -v: PASS (125 passed, all stories including previous)
- ruff check . && ruff format --check .: PASS
- All acceptance criteria: Satisfied

**Learnings:**
- The spec used `Part.from_data()` but the correct API is `Part.from_bytes(data=..., mime_type=...)` — consistent with story 2.3 learning
- add_adk_fastapi_endpoint() parameter order is (app, agent, path) not (app, path, agent) — must check function signatures
- ADKAgent.from_app() accepts the App object as first positional arg, with session_service and artifact_service as kwargs
- Phase 4 is now complete — single story for backend server done

### Story 5.1: Webapp scaffold with Next.js, CopilotKit, and dependencies
**Completed:** 2026-02-01
**Phase:** 5 - Frontend Webapp

**What Was Done:**
- Created webapp/ via create-next-app@latest with Next.js 16.1.6, React 19.2.3, TypeScript 5, Tailwind CSS 4
- Installed CopilotKit v1.50 (@copilotkit/react-core, @copilotkit/react-ui, @copilotkit/runtime)
- Installed @ag-ui/client, hono, lucide-react, clsx, tailwind-merge
- Installed dev deps: vitest, @vitejs/plugin-react, @testing-library/react, @testing-library/jest-dom, jsdom@25
- Created vitest.config.ts with jsdom environment, React plugin, and @/ path alias
- Created src/__tests__/setup.ts with @testing-library/jest-dom import
- Created src/__tests__/scaffold.test.ts with 6 tests (package.json exists, deps present, A2UI deps absent, layout exists)
- Updated src/app/layout.tsx with dark theme (className="dark"), Geist fonts, Providers wrapper, Spreadsheet Validator metadata
- Created src/app/Providers.tsx as stub (children passthrough) for future CopilotKit provider
- Simplified src/app/page.tsx to minimal Spreadsheet Validator heading
- tsconfig.json already has @/* -> ./src/* path alias from create-next-app

**Verification:**
- npm run build: PASS (Next.js 16.1.6 Turbopack, compiled successfully)
- npx vitest run: PASS (6 passed)
- All acceptance criteria: Satisfied

**Learnings:**
- jsdom@27 (latest) has ESM/CJS incompatibility with vitest — use jsdom@25 for stable testing
- create-next-app@latest now prompts for React Compiler — pipe "n" to stdin for non-interactive
- next-env.d.ts is gitignored by default in newer Next.js — don't try to stage it
- Phase 5 begins — first frontend story done
